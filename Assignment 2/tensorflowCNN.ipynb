{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CNN by Tensorflow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "\r\n",
    "# Normalise data\r\n",
    "transform = transforms.Compose(\r\n",
    "    [transforms.ToTensor(),\r\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
    "\r\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\r\n",
    "                                        download=True, transform=transform)\r\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\r\n",
    "                                          shuffle=True, num_workers=2)\r\n",
    "\r\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\r\n",
    "                                       download=True, transform=transform)\r\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\r\n",
    "                                         shuffle=False, num_workers=2)\r\n",
    "\r\n",
    "classes = ('plane', 'car', 'bird', 'cat',\r\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "\r\n",
    "class Net(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(Net, self).__init__()\r\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\r\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\r\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3)\r\n",
    "        self.pool = nn.MaxPool2d(2, 2)\r\n",
    "        self.fc1 = nn.Linear(2 * 2 * 64, 128)\r\n",
    "        self.fc2 = nn.Linear(128, 10)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        # Input - 32 * 32\r\n",
    "        x = F.relu(self.conv1(x))\r\n",
    "        # Output 30 * 30 * 32\r\n",
    "        x = self.pool(x)\r\n",
    "        # Output 15 * 15 * 32\r\n",
    "        x = F.relu(self.conv2(x))\r\n",
    "        # Output 13 * 13 * 64\r\n",
    "        x = self.pool(x)\r\n",
    "        # Output 6 * 6 * 64\r\n",
    "        x = F.relu(self.conv3(x))\r\n",
    "        # Output 4 * 4 * 64\r\n",
    "        x = self.pool(x)\r\n",
    "        # Output 2 * 2 * 64\r\n",
    "        x = x.view(-1, 2 * 2 * 64)\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        x = self.fc2(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "net = Net()\r\n",
    "print(net)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "# device = torch.device(\"cpu\")\r\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\r\n",
    "print(device)\r\n",
    "\r\n",
    "net.to(device)\r\n",
    "print(net.conv1.bias.get_device())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cpu\n",
      "-1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import torch.optim as optim\r\n",
    "\r\n",
    "net = Net()\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) #, momentum=0.9)\r\n",
    "epoch_num = 15\r\n",
    "epochs = []\r\n",
    "losses = []\r\n",
    "for epoch in range(epoch_num):  # loop over the dataset multiple times\r\n",
    "    total_loss = 0\r\n",
    "    running_loss = 0\r\n",
    "    for i, data in enumerate(trainloader, 0):\r\n",
    "        # get the inputs; data is a list of [inputs, labels]\r\n",
    "        inputs, labels = data\r\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\r\n",
    "\r\n",
    "        # zero the parameter gradients\r\n",
    "        optimizer.zero_grad()\r\n",
    "\r\n",
    "        # forward + backward + optimize\r\n",
    "        outputs = net(inputs)\r\n",
    "        loss = criterion(outputs, labels)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        total_loss += loss.item()\r\n",
    "\r\n",
    "        # print statistics\r\n",
    "        running_loss += loss.item()\r\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\r\n",
    "            print('[%d, %5d] loss: %.3f' %\r\n",
    "                  (epoch + 1, i + 1, running_loss / 500))\r\n",
    "            running_loss = 0\r\n",
    "    \r\n",
    "    epochs.append(epoch)\r\n",
    "    losses.append(total_loss / 1563)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1,   500] loss: 1.771\n",
      "[1,  1000] loss: 1.446\n",
      "[1,  1500] loss: 1.304\n",
      "[2,   500] loss: 1.192\n",
      "[2,  1000] loss: 1.123\n",
      "[2,  1500] loss: 1.070\n",
      "[3,   500] loss: 0.979\n",
      "[3,  1000] loss: 0.961\n",
      "[3,  1500] loss: 0.944\n",
      "[4,   500] loss: 0.870\n",
      "[4,  1000] loss: 0.859\n",
      "[4,  1500] loss: 0.852\n",
      "[5,   500] loss: 0.793\n",
      "[5,  1000] loss: 0.788\n",
      "[5,  1500] loss: 0.782\n",
      "[6,   500] loss: 0.719\n",
      "[6,  1000] loss: 0.738\n",
      "[6,  1500] loss: 0.738\n",
      "[7,   500] loss: 0.660\n",
      "[7,  1000] loss: 0.686\n",
      "[7,  1500] loss: 0.688\n",
      "[8,   500] loss: 0.632\n",
      "[8,  1000] loss: 0.643\n",
      "[8,  1500] loss: 0.666\n",
      "[9,   500] loss: 0.583\n",
      "[9,  1000] loss: 0.608\n",
      "[9,  1500] loss: 0.621\n",
      "[10,   500] loss: 0.552\n",
      "[10,  1000] loss: 0.575\n",
      "[10,  1500] loss: 0.586\n",
      "[11,   500] loss: 0.508\n",
      "[11,  1000] loss: 0.549\n",
      "[11,  1500] loss: 0.574\n",
      "[12,   500] loss: 0.481\n",
      "[12,  1000] loss: 0.519\n",
      "[12,  1500] loss: 0.551\n",
      "[13,   500] loss: 0.475\n",
      "[13,  1000] loss: 0.486\n",
      "[13,  1500] loss: 0.494\n",
      "[14,   500] loss: 0.437\n",
      "[14,  1000] loss: 0.478\n",
      "[14,  1500] loss: 0.489\n",
      "[15,   500] loss: 0.422\n",
      "[15,  1000] loss: 0.452\n",
      "[15,  1500] loss: 0.460\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import torch.optim as optim\r\n",
    "\r\n",
    "net = Net()\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) #, momentum=0.9)\r\n",
    "epoch_num = 15\r\n",
    "epochs = []\r\n",
    "losses = []\r\n",
    "for epoch in range(epoch_num):  # loop over the dataset multiple times\r\n",
    "    total_loss = 0\r\n",
    "    running_loss = 0\r\n",
    "    for i, data in enumerate(trainloader, 0):\r\n",
    "        # get the inputs; data is a list of [inputs, labels]\r\n",
    "        inputs, labels = data\r\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\r\n",
    "\r\n",
    "        # zero the parameter gradients\r\n",
    "        optimizer.zero_grad()\r\n",
    "\r\n",
    "        # forward + backward + optimize\r\n",
    "        outputs = net(inputs)\r\n",
    "        loss = criterion(outputs, labels)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        total_loss += loss.item()\r\n",
    "\r\n",
    "        # print statistics\r\n",
    "        running_loss += loss.item()\r\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\r\n",
    "            print('[%d, %5d] loss: %.3f' %\r\n",
    "                  (epoch + 1, i + 1, running_loss / 500))\r\n",
    "            running_loss = 0\r\n",
    "    \r\n",
    "    epochs.append(epoch)\r\n",
    "    losses.append(total_loss / 1563)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1,   500] loss: 1.771\n",
      "[1,  1000] loss: 1.446\n",
      "[1,  1500] loss: 1.304\n",
      "[2,   500] loss: 1.192\n",
      "[2,  1000] loss: 1.123\n",
      "[2,  1500] loss: 1.070\n",
      "[3,   500] loss: 0.979\n",
      "[3,  1000] loss: 0.961\n",
      "[3,  1500] loss: 0.944\n",
      "[4,   500] loss: 0.870\n",
      "[4,  1000] loss: 0.859\n",
      "[4,  1500] loss: 0.852\n",
      "[5,   500] loss: 0.793\n",
      "[5,  1000] loss: 0.788\n",
      "[5,  1500] loss: 0.782\n",
      "[6,   500] loss: 0.719\n",
      "[6,  1000] loss: 0.738\n",
      "[6,  1500] loss: 0.738\n",
      "[7,   500] loss: 0.660\n",
      "[7,  1000] loss: 0.686\n",
      "[7,  1500] loss: 0.688\n",
      "[8,   500] loss: 0.632\n",
      "[8,  1000] loss: 0.643\n",
      "[8,  1500] loss: 0.666\n",
      "[9,   500] loss: 0.583\n",
      "[9,  1000] loss: 0.608\n",
      "[9,  1500] loss: 0.621\n",
      "[10,   500] loss: 0.552\n",
      "[10,  1000] loss: 0.575\n",
      "[10,  1500] loss: 0.586\n",
      "[11,   500] loss: 0.508\n",
      "[11,  1000] loss: 0.549\n",
      "[11,  1500] loss: 0.574\n",
      "[12,   500] loss: 0.481\n",
      "[12,  1000] loss: 0.519\n",
      "[12,  1500] loss: 0.551\n",
      "[13,   500] loss: 0.475\n",
      "[13,  1000] loss: 0.486\n",
      "[13,  1500] loss: 0.494\n",
      "[14,   500] loss: 0.437\n",
      "[14,  1000] loss: 0.478\n",
      "[14,  1500] loss: 0.489\n",
      "[15,   500] loss: 0.422\n",
      "[15,  1000] loss: 0.452\n",
      "[15,  1500] loss: 0.460\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "sns.set()\r\n",
    "\r\n",
    "plt.plot(epochs, losses)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24b230acfa0>]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"251.399844pt\" version=\"1.1\" viewBox=\"0 0 373.99 251.399844\" width=\"373.99pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-09-10T02:42:53.349096</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 251.399844 \r\nL 373.99 251.399844 \r\nL 373.99 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 31.99 224.64 \r\nL 366.79 224.64 \r\nL 366.79 7.2 \r\nL 31.99 7.2 \r\nz\r\n\" style=\"fill:#eaeaf2;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 47.208182 224.64 \r\nL 47.208182 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(44.149666 242.013594)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 266 2259 \r\nQ 266 3072 433 3567 \r\nQ 600 4063 929 4331 \r\nQ 1259 4600 1759 4600 \r\nQ 2128 4600 2406 4451 \r\nQ 2684 4303 2865 4023 \r\nQ 3047 3744 3150 3342 \r\nQ 3253 2941 3253 2259 \r\nQ 3253 1453 3087 958 \r\nQ 2922 463 2592 192 \r\nQ 2263 -78 1759 -78 \r\nQ 1097 -78 719 397 \r\nQ 266 969 266 2259 \r\nz\r\nM 844 2259 \r\nQ 844 1131 1108 757 \r\nQ 1372 384 1759 384 \r\nQ 2147 384 2411 759 \r\nQ 2675 1134 2675 2259 \r\nQ 2675 3391 2411 3762 \r\nQ 2147 4134 1753 4134 \r\nQ 1366 4134 1134 3806 \r\nQ 844 3388 844 2259 \r\nz\r\n\" id=\"ArialMT-30\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 90.688701 224.64 \r\nL 90.688701 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 2 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(87.630186 242.013594)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 3222 541 \r\nL 3222 0 \r\nL 194 0 \r\nQ 188 203 259 391 \r\nQ 375 700 629 1000 \r\nQ 884 1300 1366 1694 \r\nQ 2113 2306 2375 2664 \r\nQ 2638 3022 2638 3341 \r\nQ 2638 3675 2398 3904 \r\nQ 2159 4134 1775 4134 \r\nQ 1369 4134 1125 3890 \r\nQ 881 3647 878 3216 \r\nL 300 3275 \r\nQ 359 3922 746 4261 \r\nQ 1134 4600 1788 4600 \r\nQ 2447 4600 2831 4234 \r\nQ 3216 3869 3216 3328 \r\nQ 3216 3053 3103 2787 \r\nQ 2991 2522 2730 2228 \r\nQ 2469 1934 1863 1422 \r\nQ 1356 997 1212 845 \r\nQ 1069 694 975 541 \r\nL 3222 541 \r\nz\r\n\" id=\"ArialMT-32\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-32\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 134.169221 224.64 \r\nL 134.169221 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 4 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(131.110705 242.013594)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 2069 0 \r\nL 2069 1097 \r\nL 81 1097 \r\nL 81 1613 \r\nL 2172 4581 \r\nL 2631 4581 \r\nL 2631 1613 \r\nL 3250 1613 \r\nL 3250 1097 \r\nL 2631 1097 \r\nL 2631 0 \r\nL 2069 0 \r\nz\r\nM 2069 1613 \r\nL 2069 3678 \r\nL 634 1613 \r\nL 2069 1613 \r\nz\r\n\" id=\"ArialMT-34\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-34\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 177.64974 224.64 \r\nL 177.64974 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 6 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(174.591225 242.013594)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 3184 3459 \r\nL 2625 3416 \r\nQ 2550 3747 2413 3897 \r\nQ 2184 4138 1850 4138 \r\nQ 1581 4138 1378 3988 \r\nQ 1113 3794 959 3422 \r\nQ 806 3050 800 2363 \r\nQ 1003 2672 1297 2822 \r\nQ 1591 2972 1913 2972 \r\nQ 2475 2972 2870 2558 \r\nQ 3266 2144 3266 1488 \r\nQ 3266 1056 3080 686 \r\nQ 2894 316 2569 119 \r\nQ 2244 -78 1831 -78 \r\nQ 1128 -78 684 439 \r\nQ 241 956 241 2144 \r\nQ 241 3472 731 4075 \r\nQ 1159 4600 1884 4600 \r\nQ 2425 4600 2770 4297 \r\nQ 3116 3994 3184 3459 \r\nz\r\nM 888 1484 \r\nQ 888 1194 1011 928 \r\nQ 1134 663 1356 523 \r\nQ 1578 384 1822 384 \r\nQ 2178 384 2434 671 \r\nQ 2691 959 2691 1453 \r\nQ 2691 1928 2437 2201 \r\nQ 2184 2475 1800 2475 \r\nQ 1419 2475 1153 2201 \r\nQ 888 1928 888 1484 \r\nz\r\n\" id=\"ArialMT-36\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-36\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 221.13026 224.64 \r\nL 221.13026 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 8 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(218.071744 242.013594)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 1131 2484 \r\nQ 781 2613 612 2850 \r\nQ 444 3088 444 3419 \r\nQ 444 3919 803 4259 \r\nQ 1163 4600 1759 4600 \r\nQ 2359 4600 2725 4251 \r\nQ 3091 3903 3091 3403 \r\nQ 3091 3084 2923 2848 \r\nQ 2756 2613 2416 2484 \r\nQ 2838 2347 3058 2040 \r\nQ 3278 1734 3278 1309 \r\nQ 3278 722 2862 322 \r\nQ 2447 -78 1769 -78 \r\nQ 1091 -78 675 323 \r\nQ 259 725 259 1325 \r\nQ 259 1772 486 2073 \r\nQ 713 2375 1131 2484 \r\nz\r\nM 1019 3438 \r\nQ 1019 3113 1228 2906 \r\nQ 1438 2700 1772 2700 \r\nQ 2097 2700 2305 2904 \r\nQ 2513 3109 2513 3406 \r\nQ 2513 3716 2298 3927 \r\nQ 2084 4138 1766 4138 \r\nQ 1444 4138 1231 3931 \r\nQ 1019 3725 1019 3438 \r\nz\r\nM 838 1322 \r\nQ 838 1081 952 856 \r\nQ 1066 631 1291 507 \r\nQ 1516 384 1775 384 \r\nQ 2178 384 2440 643 \r\nQ 2703 903 2703 1303 \r\nQ 2703 1709 2433 1975 \r\nQ 2163 2241 1756 2241 \r\nQ 1359 2241 1098 1978 \r\nQ 838 1716 838 1322 \r\nz\r\n\" id=\"ArialMT-38\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-38\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 264.610779 224.64 \r\nL 264.610779 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 10 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(258.493748 242.013594)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 2384 0 \r\nL 1822 0 \r\nL 1822 3584 \r\nQ 1619 3391 1289 3197 \r\nQ 959 3003 697 2906 \r\nL 697 3450 \r\nQ 1169 3672 1522 3987 \r\nQ 1875 4303 2022 4600 \r\nL 2384 4600 \r\nL 2384 0 \r\nz\r\n\" id=\"ArialMT-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 308.091299 224.64 \r\nL 308.091299 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 12 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(301.974267 242.013594)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-32\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 351.571818 224.64 \r\nL 351.571818 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 14 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(345.454787 242.013594)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-34\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 31.99 223.482489 \r\nL 366.79 223.482489 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.4 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 227.419286)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 581 0 \r\nL 581 641 \r\nL 1222 641 \r\nL 1222 0 \r\nL 581 0 \r\nz\r\n\" id=\"ArialMT-2e\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-34\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_10\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 31.99 185.883704 \r\nL 366.79 185.883704 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.6 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 189.820501)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-36\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 31.99 148.284919 \r\nL 366.79 148.284919 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.8 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 152.221716)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-38\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_12\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 31.99 110.686134 \r\nL 366.79 110.686134 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 1.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 114.622931)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 31.99 73.087349 \r\nL 366.79 73.087349 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 1.2 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 77.024146)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-32\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_14\">\r\n      <path clip-path=\"url(#p2dd314fec7)\" d=\"M 31.99 35.488565 \r\nL 366.79 35.488565 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 1.4 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 39.425362)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-34\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#p2dd314fec7)\" d=\"M 47.208182 17.083636 \r\nL 68.948442 87.13034 \r\nL 90.688701 118.26879 \r\nL 112.428961 137.08904 \r\nL 134.169221 150.818613 \r\nL 155.909481 160.824109 \r\nL 177.64974 170.670847 \r\nL 199.39 177.101244 \r\nL 221.13026 184.830506 \r\nL 242.870519 191.186093 \r\nL 264.610779 196.327502 \r\nL 286.351039 201.07976 \r\nL 308.091299 207.235794 \r\nL 329.831558 210.150022 \r\nL 351.571818 214.756364 \r\n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 31.99 224.64 \r\nL 31.99 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 366.79 224.64 \r\nL 366.79 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 31.99 224.64 \r\nL 366.79 224.64 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 31.99 7.2 \r\nL 366.79 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p2dd314fec7\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"31.99\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "correct = 0\r\n",
    "total = 0\r\n",
    "with torch.no_grad():\r\n",
    "    for data in testloader:\r\n",
    "        images, labels = data\r\n",
    "        outputs = net(images)\r\n",
    "        _, predicted = torch.max(outputs.data, 1)\r\n",
    "        total += labels.size(0)\r\n",
    "        correct += (predicted == labels).sum().item()\r\n",
    "\r\n",
    "print(f\"Accuracy of the network on the 10000 test images: {correct / total * 100:.1f}%\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network on the 10000 test images: 72.3%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import pandas as pd\r\n",
    "dict = {\"Epoch\":epochs, \"Loss\":losses}\r\n",
    "df = pd.DataFrame(dict)\r\n",
    "df.to_csv('tensorAdam.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "PATH = './tensorFlow.pth'\r\n",
    "torch.save(net.state_dict(), PATH)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "e7be37f0d4f974b56952a9e3db86de64bb52fb5182b91743688a15180307762f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}